{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1238ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pongp\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pongp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: model/binary_128_0.50_labels_ver2.txt : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 410\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    409\u001b[0m     findPlate \u001b[38;5;241m=\u001b[39m PlateFinder(minPlateArea\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4100\u001b[39m, maxPlateArea\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15000\u001b[39m)\n\u001b[1;32m--> 410\u001b[0m     model \u001b[38;5;241m=\u001b[39m OCR(modelFile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/binary_128_0.50_ver3.pb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    411\u001b[0m                 labelFile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/binary_128_0.50_labels_ver2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    413\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpongp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSenior\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataSet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdownload.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[0;32m    414\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n",
      "Cell \u001b[1;32mIn[1], line 335\u001b[0m, in \u001b[0;36mOCR.__init__\u001b[1;34m(self, modelFile, labelFile)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_file \u001b[38;5;241m=\u001b[39m modelFile \n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_file \u001b[38;5;241m=\u001b[39m labelFile \n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_label(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_file) \n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_file) \n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession(graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, \n\u001b[0;32m    338\u001b[0m \t\t\t\t\t\t\t\tconfig\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mConfigProto())\n",
      "Cell \u001b[1;32mIn[1], line 355\u001b[0m, in \u001b[0;36mOCR.load_label\u001b[1;34m(self, labelFile)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, labelFile): \n\u001b[0;32m    354\u001b[0m \tlabel \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m--> 355\u001b[0m \tproto_as_ascii_lines \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(labelFile)\u001b[38;5;241m.\u001b[39mreadlines() \n\u001b[0;32m    357\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m proto_as_ascii_lines: \n\u001b[0;32m    358\u001b[0m \t\tlabel\u001b[38;5;241m.\u001b[39mappend(l\u001b[38;5;241m.\u001b[39mrstrip()) \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:174\u001b[0m, in \u001b[0;36mFileIO.readlines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadlines\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns all lines from the file in a list.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preread_check()\n\u001b[0;32m    175\u001b[0m   lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m _pywrap_file_io\u001b[38;5;241m.\u001b[39mBufferedInputStream(\n\u001b[0;32m     78\u001b[0m     compat\u001b[38;5;241m.\u001b[39mpath_to_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name), \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m512\u001b[39m)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: model/binary_128_0.50_labels_ver2.txt : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from skimage.filters import threshold_local \n",
    "import tensorflow as tf \n",
    "from skimage import measure \n",
    "import imutils \n",
    "import os \n",
    "\n",
    "def sort_cont(character_contours): \n",
    "\t\"\"\" \n",
    "\tTo sort contours \n",
    "\t\"\"\"\n",
    "\ti = 0\n",
    "\tboundingBoxes = [cv2.boundingRect(c) for c in character_contours] \n",
    "\t\n",
    "\t(character_contours, boundingBoxes) = zip(*sorted(zip(character_contours, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tboundingBoxes), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tkey = lambda b: b[1][i], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treverse = False)) \n",
    "\t\n",
    "\treturn character_contours \n",
    "\n",
    "\n",
    "def segment_chars(plate_img, fixed_width): \n",
    "\t\n",
    "\t\"\"\" \n",
    "\textract Value channel from the HSV format \n",
    "\tof image and apply adaptive thresholding \n",
    "\tto reveal the characters on the license plate \n",
    "\t\"\"\"\n",
    "\tV = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2] \n",
    "\n",
    "\tthresh = cv2.adaptiveThreshold(V, 255, \n",
    "\t\t\t\t\t\t\t\tcv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "\t\t\t\t\t\t\t\tcv2.THRESH_BINARY, \n",
    "\t\t\t\t\t\t\t\t11, 2) \n",
    "\t\n",
    "\tthresh = cv2.bitwise_not(thresh) \n",
    "\n",
    "\t# resize the license plate region to \n",
    "\t# a canoncial size \n",
    "\tplate_img = imutils.resize(plate_img, width = fixed_width) \n",
    "\tthresh = imutils.resize(thresh, width = fixed_width) \n",
    "\tbgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "\t# perform a connected components analysis \n",
    "\t# and initialize the mask to store the locations \n",
    "\t# of the character candidates \n",
    "\tlabels = measure.label(thresh, background = 0) \n",
    "\n",
    "\tcharCandidates = np.zeros(thresh.shape, dtype ='uint8') \n",
    "\n",
    "\t# loop over the unique components \n",
    "\tcharacters = [] \n",
    "\tfor label in np.unique(labels): \n",
    "\t\t\n",
    "\t\t# if this is the background label, ignore it \n",
    "\t\tif label == 0: \n",
    "\t\t\tcontinue\n",
    "\t\t# otherwise, construct the label mask to display \n",
    "\t\t# only connected components for the current label, \n",
    "\t\t# then find contours in the label mask \n",
    "\t\tlabelMask = np.zeros(thresh.shape, dtype ='uint8') \n",
    "\t\tlabelMask[labels == label] = 255\n",
    "\n",
    "\t\tcnts = cv2.findContours(labelMask, \n",
    "\t\t\t\t\tcv2.RETR_EXTERNAL, \n",
    "\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "\t\tcnts = cnts[1] if imutils.is_cv3() else cnts[0] \n",
    "\n",
    "\t\t# ensure at least one contour was found in the mask \n",
    "\t\tif len(cnts) > 0: \n",
    "\n",
    "\t\t\t# grab the largest contour which corresponds \n",
    "\t\t\t# to the component in the mask, then grab the \n",
    "\t\t\t# bounding box for the contour \n",
    "\t\t\tc = max(cnts, key = cv2.contourArea) \n",
    "\t\t\t(boxX, boxY, boxW, boxH) = cv2.boundingRect(c) \n",
    "\n",
    "\t\t\t# compute the aspect ratio, solodity, and \n",
    "\t\t\t# height ration for the component \n",
    "\t\t\taspectRatio = boxW / float(boxH) \n",
    "\t\t\tsolidity = cv2.contourArea(c) / float(boxW * boxH) \n",
    "\t\t\theightRatio = boxH / float(plate_img.shape[0]) \n",
    "\n",
    "\t\t\t# determine if the aspect ratio, solidity, \n",
    "\t\t\t# and height of the contour pass the rules \n",
    "\t\t\t# tests \n",
    "\t\t\tkeepAspectRatio = aspectRatio < 1.0\n",
    "\t\t\tkeepSolidity = solidity > 0.15\n",
    "\t\t\tkeepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
    "\n",
    "\t\t\t# check to see if the component passes \n",
    "\t\t\t# all the tests \n",
    "\t\t\tif keepAspectRatio and keepSolidity and keepHeight and boxW > 14: \n",
    "\t\t\t\t\n",
    "\t\t\t\t# compute the convex hull of the contour \n",
    "\t\t\t\t# and draw it on the character candidates \n",
    "\t\t\t\t# mask \n",
    "\t\t\t\thull = cv2.convexHull(c) \n",
    "\n",
    "\t\t\t\tcv2.drawContours(charCandidates, [hull], -1, 255, -1) \n",
    "\n",
    "\tcontours, hier = cv2.findContours(charCandidates, \n",
    "\t\t\t\t\t\t\t\t\t\tcv2.RETR_EXTERNAL, \n",
    "\t\t\t\t\t\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE) \n",
    "\t\n",
    "\tif contours: \n",
    "\t\tcontours = sort_cont(contours) \n",
    "\t\t\n",
    "\t\t# value to be added to each dimension \n",
    "\t\t# of the character \n",
    "\t\taddPixel = 4\n",
    "\t\tfor c in contours: \n",
    "\t\t\t(x, y, w, h) = cv2.boundingRect(c) \n",
    "\t\t\tif y > addPixel: \n",
    "\t\t\t\ty = y - addPixel \n",
    "\t\t\telse: \n",
    "\t\t\t\ty = 0\n",
    "\t\t\tif x > addPixel: \n",
    "\t\t\t\tx = x - addPixel \n",
    "\t\t\telse: \n",
    "\t\t\t\tx = 0\n",
    "\t\t\ttemp = bgr_thresh[y:y + h + (addPixel * 2), \n",
    "\t\t\t\t\t\t\tx:x + w + (addPixel * 2)] \n",
    "\n",
    "\t\t\tcharacters.append(temp) \n",
    "\t\t\t\n",
    "\t\treturn characters \n",
    "\t\n",
    "\telse: \n",
    "\t\treturn None\n",
    "\n",
    "\n",
    "\n",
    "class PlateFinder: \n",
    "\tdef __init__(self, minPlateArea, maxPlateArea): \n",
    "\t\t\n",
    "\t\t# minimum area of the plate \n",
    "\t\tself.min_area = minPlateArea \n",
    "\t\t\n",
    "\t\t# maximum area of the plate \n",
    "\t\tself.max_area = maxPlateArea \n",
    "\n",
    "\t\tself.element_structure = cv2.getStructuringElement( \n",
    "\t\t\t\t\t\t\tshape = cv2.MORPH_RECT, ksize =(22, 3)) \n",
    "\n",
    "\tdef preprocess(self, input_img): \n",
    "\t\t\n",
    "\t\timgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0) \n",
    "\t\t\n",
    "\t\t# convert to gray \n",
    "\t\tgray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY) \n",
    "\t\t\n",
    "\t\t# sobelX to get the vertical edges \n",
    "\t\tsobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize = 3) \n",
    "\t\t\n",
    "\t\t# otsu's thresholding \n",
    "\t\tret2, threshold_img = cv2.threshold(sobelx, 0, 255, \n",
    "\t\t\t\t\t\tcv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
    "\n",
    "\t\telement = self.element_structure \n",
    "\t\tmorph_n_thresholded_img = threshold_img.copy() \n",
    "\t\tcv2.morphologyEx(src = threshold_img, \n",
    "\t\t\t\t\t\top = cv2.MORPH_CLOSE, \n",
    "\t\t\t\t\t\tkernel = element, \n",
    "\t\t\t\t\t\tdst = morph_n_thresholded_img) \n",
    "\t\t\n",
    "\t\treturn morph_n_thresholded_img \n",
    "\n",
    "\tdef extract_contours(self, after_preprocess): \n",
    "\t\t\n",
    "\t\tcontours, _ = cv2.findContours(after_preprocess, \n",
    "\t\t\t\t\t\t\t\t\t\tmode = cv2.RETR_EXTERNAL, \n",
    "\t\t\t\t\t\t\t\t\t\tmethod = cv2.CHAIN_APPROX_NONE) \n",
    "\t\treturn contours \n",
    "\n",
    "\tdef clean_plate(self, plate): \n",
    "\t\t\n",
    "\t\tgray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY) \n",
    "\t\tthresh = cv2.adaptiveThreshold(gray, \n",
    "\t\t\t\t\t\t\t\t\t255, \n",
    "\t\t\t\t\t\t\t\t\tcv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "\t\t\t\t\t\t\t\t\tcv2.THRESH_BINARY, \n",
    "\t\t\t\t\t\t\t\t\t11, 2) \n",
    "\t\t\n",
    "\t\tcontours, _ = cv2.findContours(thresh.copy(), \n",
    "\t\t\t\t\t\t\t\t\t\tcv2.RETR_EXTERNAL, \n",
    "\t\t\t\t\t\t\t\t\t\tcv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "\t\tif contours: \n",
    "\t\t\tareas = [cv2.contourArea(c) for c in contours] \n",
    "\t\t\t\n",
    "\t\t\t# index of the largest contour in the area \n",
    "\t\t\t# array \n",
    "\t\t\tmax_index = np.argmax(areas) \n",
    "\n",
    "\t\t\tmax_cnt = contours[max_index] \n",
    "\t\t\tmax_cntArea = areas[max_index] \n",
    "\t\t\tx, y, w, h = cv2.boundingRect(max_cnt) \n",
    "\t\t\trect = cv2.minAreaRect(max_cnt) \n",
    "\t\t\tif not self.ratioCheck(max_cntArea, plate.shape[1], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tplate.shape[0]): \n",
    "\t\t\t\treturn plate, False, None\n",
    "\t\t\t\n",
    "\t\t\treturn plate, True, [x, y, w, h] \n",
    "\t\t\n",
    "\t\telse: \n",
    "\t\t\treturn plate, False, None\n",
    "\n",
    "\n",
    "\n",
    "\tdef check_plate(self, input_img, contour): \n",
    "\t\t\n",
    "\t\tmin_rect = cv2.minAreaRect(contour) \n",
    "\t\t\n",
    "\t\tif self.validateRatio(min_rect): \n",
    "\t\t\tx, y, w, h = cv2.boundingRect(contour) \n",
    "\t\t\tafter_validation_img = input_img[y:y + h, x:x + w] \n",
    "\t\t\tafter_clean_plate_img, plateFound, coordinates = self.clean_plate( \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tafter_validation_img) \n",
    "\t\t\t\n",
    "\t\t\tif plateFound: \n",
    "\t\t\t\tcharacters_on_plate = self.find_characters_on_plate( \n",
    "\t\t\t\t\t\t\t\t\t\t\tafter_clean_plate_img) \n",
    "\t\t\t\t\n",
    "\t\t\t\tif (characters_on_plate is not None and len(characters_on_plate) == 8): \n",
    "\t\t\t\t\tx1, y1, w1, h1 = coordinates \n",
    "\t\t\t\t\tcoordinates = x1 + x, y1 + y \n",
    "\t\t\t\t\tafter_check_plate_img = after_clean_plate_img \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\treturn after_check_plate_img, characters_on_plate, coordinates \n",
    "\t\t\n",
    "\t\treturn None, None, None\n",
    "\n",
    "\n",
    "\n",
    "\tdef find_possible_plates(self, input_img): \n",
    "\t\t\n",
    "\t\t\"\"\" \n",
    "\t\tFinding all possible contours that can be plates \n",
    "\t\t\"\"\"\n",
    "\t\tplates = [] \n",
    "\t\tself.char_on_plate = [] \n",
    "\t\tself.corresponding_area = [] \n",
    "\n",
    "\t\tself.after_preprocess = self.preprocess(input_img) \n",
    "\t\tpossible_plate_contours = self.extract_contours(self.after_preprocess) \n",
    "\n",
    "\t\tfor cnts in possible_plate_contours: \n",
    "\t\t\tplate, characters_on_plate, coordinates = self.check_plate(input_img, cnts) \n",
    "\t\t\t\n",
    "\t\t\tif plate is not None: \n",
    "\t\t\t\tplates.append(plate) \n",
    "\t\t\t\tself.char_on_plate.append(characters_on_plate) \n",
    "\t\t\t\tself.corresponding_area.append(coordinates) \n",
    "\n",
    "\t\tif (len(plates) > 0): \n",
    "\t\t\treturn plates \n",
    "\t\t\n",
    "\t\telse: \n",
    "\t\t\treturn None\n",
    "\n",
    "\tdef find_characters_on_plate(self, plate): \n",
    "\n",
    "\t\tcharactersFound = segment_chars(plate, 400) \n",
    "\t\tif charactersFound: \n",
    "\t\t\treturn charactersFound \n",
    "\n",
    "\t# PLATE FEATURES \n",
    "\tdef ratioCheck(self, area, width, height): \n",
    "\t\t\n",
    "\t\tmin = self.min_area \n",
    "\t\tmax = self.max_area \n",
    "\n",
    "\t\tratioMin = 3\n",
    "\t\tratioMax = 6\n",
    "\n",
    "\t\tratio = float(width) / float(height) \n",
    "\t\t\n",
    "\t\tif ratio < 1: \n",
    "\t\t\tratio = 1 / ratio \n",
    "\t\t\n",
    "\t\tif (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax): \n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "\tdef preRatioCheck(self, area, width, height): \n",
    "\t\t\n",
    "\t\tmin = self.min_area \n",
    "\t\tmax = self.max_area \n",
    "\n",
    "\t\tratioMin = 2.5\n",
    "\t\tratioMax = 7\n",
    "\n",
    "\t\tratio = float(width) / float(height) \n",
    "\t\t\n",
    "\t\tif ratio < 1: \n",
    "\t\t\tratio = 1 / ratio \n",
    "\n",
    "\t\tif (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax): \n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "\tdef validateRatio(self, rect): \n",
    "\t\t(x, y), (width, height), rect_angle = rect \n",
    "\n",
    "\t\tif (width > height): \n",
    "\t\t\tangle = -rect_angle \n",
    "\t\telse: \n",
    "\t\t\tangle = 90 + rect_angle \n",
    "\n",
    "\t\tif angle > 15: \n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\tif (height == 0 or width == 0): \n",
    "\t\t\treturn False\n",
    "\n",
    "\t\tarea = width * height \n",
    "\t\t\n",
    "\t\tif not self.preRatioCheck(area, width, height): \n",
    "\t\t\treturn False\n",
    "\t\telse: \n",
    "\t\t\treturn True\n",
    "\n",
    "class OCR: \n",
    "\t\n",
    "\tdef __init__(self, modelFile, labelFile): \n",
    "\t\t\n",
    "\t\tself.model_file = modelFile \n",
    "\t\tself.label_file = labelFile \n",
    "\t\tself.label = self.load_label(self.label_file) \n",
    "\t\tself.graph = self.load_graph(self.model_file) \n",
    "\t\tself.sess = tf.compat.v1.Session(graph=self.graph, \n",
    "\t\t\t\t\t\t\t\t\t\tconfig=tf.compat.v1.ConfigProto()) \n",
    "\n",
    "\tdef load_graph(self, modelFile): \n",
    "\t\t\n",
    "\t\tgraph = tf.Graph() \n",
    "\t\tgraph_def = tf.compat.v1.GraphDef() \n",
    "\t\t\n",
    "\t\twith open(modelFile, \"rb\") as f: \n",
    "\t\t\tgraph_def.ParseFromString(f.read()) \n",
    "\t\t\n",
    "\t\twith graph.as_default(): \n",
    "\t\t\ttf.import_graph_def(graph_def) \n",
    "\t\t\n",
    "\t\treturn graph \n",
    "\n",
    "\tdef load_label(self, labelFile): \n",
    "\t\tlabel = [] \n",
    "\t\tproto_as_ascii_lines = tf.io.gfile.GFile(labelFile).readlines() \n",
    "\t\t\n",
    "\t\tfor l in proto_as_ascii_lines: \n",
    "\t\t\tlabel.append(l.rstrip()) \n",
    "\t\t\n",
    "\t\treturn label \n",
    "\n",
    "\tdef convert_tensor(self, image, imageSizeOuput): \n",
    "\t\t\"\"\" \n",
    "\t\ttakes an image and transform it in tensor \n",
    "\t\t\"\"\"\n",
    "\t\timage = cv2.resize(image, \n",
    "\t\t\t\t\t\tdsize =(imageSizeOuput, \n",
    "\t\t\t\t\t\t\t\timageSizeOuput), \n",
    "\t\t\t\t\t\tinterpolation = cv2.INTER_CUBIC) \n",
    "\t\t\n",
    "\t\tnp_image_data = np.asarray(image) \n",
    "\t\tnp_image_data = cv2.normalize(np_image_data.astype('float'), \n",
    "\t\t\t\t\t\t\t\t\tNone, -0.5, .5, \n",
    "\t\t\t\t\t\t\t\t\tcv2.NORM_MINMAX) \n",
    "\t\t\n",
    "\t\tnp_final = np.expand_dims(np_image_data, axis = 0) \n",
    "\t\t\n",
    "\t\treturn np_final \n",
    "\n",
    "\tdef label_image(self, tensor): \n",
    "\n",
    "\t\tinput_name = \"import/input\"\n",
    "\t\toutput_name = \"import/final_result\"\n",
    "\n",
    "\t\tinput_operation = self.graph.get_operation_by_name(input_name) \n",
    "\t\toutput_operation = self.graph.get_operation_by_name(output_name) \n",
    "\n",
    "\t\tresults = self.sess.run(output_operation.outputs[0], \n",
    "\t\t\t\t\t\t\t\t{input_operation.outputs[0]: tensor}) \n",
    "\t\tresults = np.squeeze(results) \n",
    "\t\tlabels = self.label \n",
    "\t\ttop = results.argsort()[-1:][::-1] \n",
    "\t\t\n",
    "\t\treturn labels[top[0]] \n",
    "\n",
    "\tdef label_image_list(self, listImages, imageSizeOuput): \n",
    "\t\tplate = \"\" \n",
    "\t\t\n",
    "\t\tfor img in listImages: \n",
    "\t\t\t\n",
    "\t\t\tif cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "\t\t\t\tbreak\n",
    "\t\t\tplate = plate + self.label_image(self.convert_tensor(img, imageSizeOuput)) \n",
    "\t\t\n",
    "\t\treturn plate, len(plate) \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    findPlate = PlateFinder(minPlateArea=4100, maxPlateArea=15000)\n",
    "    model = OCR(modelFile=\"model/binary_128_0.50_ver3.pb\", \n",
    "                labelFile=\"model/binary_128_0.50_labels_ver2.txt\")\n",
    "\n",
    "    image_path = r\"C:\\Users\\pongp\\Downloads\\Senior\\DataSet\\download.jpg\"  # Replace with your image path\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    possible_plates = findPlate.find_possible_plates(img)\n",
    "    if possible_plates is not None:\n",
    "        for i, p in enumerate(possible_plates):\n",
    "            chars_on_plate = findPlate.char_on_plate[i]\n",
    "            recognized_plate, _ = model.label_image_list(\n",
    "                chars_on_plate, imageSizeOuput=128)\n",
    "\n",
    "            print(recognized_plate)\n",
    "            cv2.imshow('plate', p)\n",
    "\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8967907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
